{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read credentials from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jira import JIRA, JIRAError\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading credentials file JSON\n",
    "with open('credential_jira.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "user = credentials['user']\n",
    "password = credentials['apikey']\n",
    "link = credentials['link']\n",
    "project_key = credentials['project_key'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute JQL query to obtain info from Jira Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tickets from IBRR Jira project...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Jira authentication \n",
    "jira = JIRA(server=link, basic_auth=(user, password))\n",
    "\n",
    "# Querying data using JQL language\n",
    "jql_query = f'project = {project_key} ORDER BY created ASC'\n",
    "\n",
    "# Pagination of all isseus from Jira project\n",
    "block_size = 100\n",
    "block_num = 0\n",
    "\n",
    "# Opening CSV file for writing all issues in there\n",
    "print(f\"Extracting tickets from {project_key} Jira project...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1384 tickets were created and written in jira_issues.csv\n"
     ]
    }
   ],
   "source": [
    "with open('jira_issues.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Writing CSV Column names\n",
    "    writer.writerow([\n",
    "        'key', \n",
    "        'tool_value',\n",
    "        'area',\n",
    "        'sprint',\n",
    "        'summary', \n",
    "        'status', \n",
    "        'assignee', \n",
    "        'reporter', \n",
    "        'created', \n",
    "        'updated', \n",
    "        #'custom_create_date',\n",
    "        #'custom_end_date',\n",
    "        'date_diff_days',\n",
    "        'priority', \n",
    "        'issue_type', \n",
    "        #'labels', \n",
    "        #'comments', \n",
    "    ])\n",
    "\n",
    "    while True:\n",
    "        start_idx = block_num * block_size\n",
    "        try:\n",
    "            issues = jira.search_issues(jql_query, startAt=start_idx, maxResults=block_size, expand='changelog')\n",
    "        except JIRAError as e:\n",
    "            if e.status_code == 404:\n",
    "                print(f\"Ignoring not found tickets {block_num}\")\n",
    "                break  # Quit while if face 404 error\n",
    "            else:\n",
    "                raise  # Rerun exception if error was |= from 404 error\n",
    "        else:\n",
    "            if not issues:\n",
    "                break\n",
    "            for issue in issues:\n",
    "                # RegExing main custom fileds\n",
    "                tool_pattern = r\"value='(.*?)'\"\n",
    "                tool_match = re.search(tool_pattern, str(issue.fields.customfield_11897)) #Tool\n",
    "                tool_value = tool_match.group(1) if tool_match else None\n",
    "\n",
    "                area_pattern = r\"value='(.*?)'\"\n",
    "                area_match = re.search(area_pattern, str(issue.fields.customfield_11896)) #Area\n",
    "                area_value = area_match.group(1) if area_match else None\n",
    "\n",
    "                sprint_field = issue.fields.customfield_10007\n",
    "                if isinstance(sprint_field, list):\n",
    "                    sprint_value = ', '.join([str(sprint) for sprint in sprint_field])\n",
    "                else:\n",
    "                    sprint_value = str(sprint_field)\n",
    "\n",
    "                # Converting dates (Created e Updated) in a date filed\n",
    "                created_date = datetime.strptime(issue.fields.created, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                updated_date = datetime.strptime(issue.fields.updated, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                date_diff_days = (updated_date - created_date).days\n",
    "\n",
    "                #custom_create_date = datetime.strptime(issue.fields.customfield_11930, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                #custom_end_date = datetime.strptime(issue.fields.customfield_11931, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "\n",
    "                writer.writerow([\n",
    "                    issue.key,\n",
    "                    tool_value,\n",
    "                    area_value,\n",
    "                    sprint_value,\n",
    "                    issue.fields.summary,\n",
    "                    issue.fields.status.name,\n",
    "                    issue.fields.assignee.displayName if issue.fields.assignee else 'Unassigned',\n",
    "                    issue.fields.reporter.displayName,\n",
    "                    created_date,\n",
    "                    updated_date,\n",
    "                    #issue.fields.customfield_11930, #custom_create_date\n",
    "                    #issue.fields.customfield_11931, #custom_end_date\n",
    "                    date_diff_days,\n",
    "                    issue.fields.priority.name if issue.fields.priority else 'None',\n",
    "                    issue.fields.issuetype.name,\n",
    "                    #issue.fields.labels if issue.fields.labels else '',\n",
    "                    #'\\n'.join([comment.body for comment in issue.fields.comment.comments]) if issue.fields.comment.comments else '',\n",
    "                ])\n",
    "            block_num += 1\n",
    "\n",
    "df = pd.read_csv('./jira_issues.csv')\n",
    "no_of_rows = df['key'].count()\n",
    "print(f\"{no_of_rows} tickets were created and written in jira_issues.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting values\n",
    "\n",
    "Counting how many single values have for the entire csv, for all the column that I want to anonymize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count distinct for main columns to anonymizing:\n",
      "tool_value    10\n",
      "area          16\n",
      "assignee      10\n",
      "reporter      16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "interested_columns = ['tool_value', 'area', 'assignee','reporter',]\n",
    "df = pd.read_csv('./jira_issues.csv',usecols=interested_columns)\n",
    "\n",
    "distinct_counts = df[interested_columns].nunique()\n",
    "\n",
    "# Stampare i risultati\n",
    "print(\"Count distinct for main columns to anonymizing:\")\n",
    "print(distinct_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymizing data\n",
    "\n",
    "### Assignee names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Richard Newton\n",
      "1       Michael Alexander\n",
      "2          Richard Newton\n",
      "3       Michael Alexander\n",
      "4          Richard Newton\n",
      "              ...        \n",
      "1379      William Simpson\n",
      "1380    Michael Alexander\n",
      "1381    Michael Alexander\n",
      "1382    Michael Alexander\n",
      "1383      Renee Fernandez\n",
      "Name: anonymized_assignee, Length: 1384, dtype: object\n",
      "\n",
      "Unique values for anonymized_reporter column are: 10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Leggi il file CSV dei problemi Jira\n",
    "#df = pd.read_csv('./jira_issues.csv')\n",
    "\n",
    "# Inizializza il generatore di nomi casuali\n",
    "faker = Faker()\n",
    "\n",
    "# Dizionario per memorizzare la corrispondenza tra nomi originali e anonimizzati\n",
    "name_dictionary = {}\n",
    "\n",
    "# Funzione per anonimizzare un nome\n",
    "def anonymize_name(name):\n",
    "    if name not in name_dictionary:\n",
    "        # Genera un nuovo nome anonimo se non è già stato anonimizzato\n",
    "        anonymized_name = faker.name()\n",
    "        name_dictionary[name] = anonymized_name\n",
    "    return name_dictionary[name]\n",
    "\n",
    "# Applicare la funzione di anonimizzazione alla colonna 'assignee'\n",
    "df['anonymized_assignee'] = df['assignee'].apply(anonymize_name)\n",
    "\n",
    "print(df['anonymized_assignee'])\n",
    "\n",
    "# Check if the count distinct of the anonymized columsn are the same of original ones\n",
    "\n",
    "distinct_count_anonymized_assignee = len(set(df['anonymized_assignee']))\n",
    "print(f\"\\nUnique values for anonymized_reporter column are: {distinct_count_anonymized_assignee}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Tool F\n",
      "1       Tool D\n",
      "2       Tool F\n",
      "3       Tool F\n",
      "4       Tool F\n",
      "         ...  \n",
      "1379    Tool F\n",
      "1380    Tool D\n",
      "1381    Tool F\n",
      "1382    Tool F\n",
      "1383    Tool D\n",
      "Name: anonymized_tool, Length: 1384, dtype: object\n",
      "\n",
      "Unique values for anonymized_reporter column are: 4\n"
     ]
    }
   ],
   "source": [
    "# Esempio di lista di nomi da anonimizzare per i tool\n",
    "anonymize_tool_list = [\n",
    "    \"Tool A\", \n",
    "    \"Tool B\", \n",
    "    \"Tool C\",\n",
    "    \"Tool D\", \n",
    "    \"Tool E\", \n",
    "    \"Tool F\",\n",
    "]\n",
    "\n",
    "# Dizionario per memorizzare le corrispondenze tra nomi originali e anonimizzati per i tool\n",
    "tool_dictionary = {}\n",
    "\n",
    "# Funzione per anonimizzare un tool\n",
    "def anonymize_tool(tool):\n",
    "    if tool not in tool_dictionary:\n",
    "        # Seleziona un nome anonimizzato dalla lista in modo casuale\n",
    "        anonymized_tool = random.choice(anonymize_tool_list)\n",
    "        tool_dictionary[tool] = anonymized_tool\n",
    "    return tool_dictionary[tool]\n",
    "\n",
    "# Applicare la funzione di anonimizzazione ai tool\n",
    "df['anonymized_tool'] = df['tool_value'].apply(anonymize_tool)\n",
    "\n",
    "# Visualizza il DataFrame con le colonne 'assignee_anonymized' e 'anonymized_tool'\n",
    "print(df['anonymized_tool'])\n",
    "\n",
    "# Check if the count distinct of the anonymized columsn are the same of original ones\n",
    "\n",
    "distinct_count_anonymized_tool = len(set(df['anonymized_tool']))\n",
    "print(f\"\\nUnique values for anonymized_reporter column are: {distinct_count_anonymized_tool}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           Compliance and Regulation\n",
      "1                  Project Management\n",
      "2               Business Intelligence\n",
      "3       Innovation and Sustainability\n",
      "4           Compliance and Regulation\n",
      "                    ...              \n",
      "1379                       Production\n",
      "1380                  Data Governance\n",
      "1381                  Data Governance\n",
      "1382                       Production\n",
      "1383               Project Management\n",
      "Name: anonymized_area, Length: 1384, dtype: object\n",
      "\n",
      "Unique values for anonymized_reporter column are: 10\n"
     ]
    }
   ],
   "source": [
    "# Esempio di lista di nomi da anonimizzare per i tool\n",
    "anonymize_area_list = [\n",
    "    \"Marketing\",\n",
    "    \"Sales\",\n",
    "    \"Finance\",\n",
    "    \"Human Resources\",\n",
    "    \"Production\",\n",
    "    \"Logistics\",\n",
    "    \"Research and Development\",\n",
    "    \"Customer Service\",\n",
    "    \"Project Management\",\n",
    "    \"Information Technology (IT)\",\n",
    "    \"Quality Assurance\",\n",
    "    \"Data Governance\",\n",
    "    \"Strategic Planning\",\n",
    "    \"Compliance and Regulation\",\n",
    "    \"Innovation and Sustainability\",\n",
    "    \"Business Intelligence\"\n",
    "]\n",
    "\n",
    "# Dizionario per memorizzare le corrispondenze tra nomi originali e anonimizzati per i tool\n",
    "area_dictionary = {}\n",
    "\n",
    "# Funzione per anonimizzare un tool\n",
    "def anonymize_area(area):\n",
    "    if area not in area_dictionary:\n",
    "        # Seleziona un nome anonimizzato dalla lista in modo casuale\n",
    "        anonymized_area = random.choice(anonymize_area_list)\n",
    "        area_dictionary[area] = anonymized_area\n",
    "    return area_dictionary[area]\n",
    "\n",
    "# Applicare la funzione di anonimizzazione ai tool\n",
    "df['anonymized_area'] = df['area'].apply(anonymize_area)\n",
    "\n",
    "# Visualizza il DataFrame con le colonne 'assignee_anonymized' e 'anonymized_tool'\n",
    "print(df['anonymized_area'])\n",
    "\n",
    "# Check if the count distinct of the anonymized columsn are the same of original ones\n",
    "\n",
    "distinct_count_anonymized_area = len(set(df['anonymized_area']))\n",
    "print(f\"\\nUnique values for anonymized_reporter column are: {distinct_count_anonymized_area}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          James Dennis\n",
      "1              Lisa Lee\n",
      "2          Alison Lewis\n",
      "3          Alison Lewis\n",
      "4          Alison Lewis\n",
      "             ...       \n",
      "1379    Steven Morrison\n",
      "1380       Alison Lewis\n",
      "1381       Alison Lewis\n",
      "1382       Alison Lewis\n",
      "1383           Lisa Lee\n",
      "Name: anonymized_reporter, Length: 1384, dtype: object\n",
      "\n",
      "Unique values for anonymized_reporter columnare: 16\n"
     ]
    }
   ],
   "source": [
    "# Inizializza il generatore di nomi casuali\n",
    "faker = Faker()\n",
    "\n",
    "# Dizionario per memorizzare la corrispondenza tra nomi originali e anonimizzati\n",
    "reporter_dictionary = {}\n",
    "\n",
    "# Funzione per anonimizzare un nome\n",
    "def anonymize_reporter(reporter):\n",
    "    if reporter not in reporter_dictionary:\n",
    "        # Genera un nuovo nome anonimo se non è già stato anonimizzato\n",
    "        anonymized_reporter = faker.name()\n",
    "        reporter_dictionary[reporter] = anonymized_reporter\n",
    "    return reporter_dictionary[reporter]\n",
    "\n",
    "# Applicare la funzione di anonimizzazione alla colonna 'assignee'\n",
    "df['anonymized_reporter'] = df['reporter'].apply(anonymize_reporter)\n",
    "\n",
    "print(df['anonymized_reporter'])\n",
    "\n",
    "# Check if the count distinct of the anonymized columsn are the same of original ones\n",
    "\n",
    "distinct_count_reporter_area = len(set(df['anonymized_reporter']))\n",
    "print(f\"\\nUnique values for anonymized_reporter columnare: {distinct_count_reporter_area}\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
