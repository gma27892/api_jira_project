{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read credentials from JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from jira import JIRA, JIRAError\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading credentials file JSON\n",
    "with open('credential_jira.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "user = credentials['user']\n",
    "password = credentials['apikey']\n",
    "link = credentials['link']\n",
    "project_key = credentials['project_key'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute JQL query to obtain info from Jira Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tickets from IBRR Jira project...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Jira authentication \n",
    "jira = JIRA(server=link, basic_auth=(user, password))\n",
    "\n",
    "# Querying data using JQL language\n",
    "jql_query = f'project = {project_key} ORDER BY created ASC'\n",
    "\n",
    "# Pagination of all isseus from Jira project\n",
    "block_size = 100\n",
    "block_num = 0\n",
    "\n",
    "# Opening CSV file for writing all issues in there\n",
    "print(f\"Extracting tickets from {project_key} Jira project...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370 tickets were created and written in jira_issues.csv\n"
     ]
    }
   ],
   "source": [
    "with open('jira_issues.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Writing CSV Column names\n",
    "    writer.writerow([\n",
    "        'key', \n",
    "        'tool_value',\n",
    "        'area',\n",
    "        'sprint',\n",
    "        'summary', \n",
    "        'status', \n",
    "        'assignee', \n",
    "        'reporter', \n",
    "        'created', \n",
    "        'updated', \n",
    "        #'custom_create_date',\n",
    "        #'custom_end_date',\n",
    "        'date_diff_days',\n",
    "        'priority', \n",
    "        'issue_type', \n",
    "        #'labels', \n",
    "        #'comments', \n",
    "    ])\n",
    "\n",
    "    while True:\n",
    "        start_idx = block_num * block_size\n",
    "        try:\n",
    "            issues = jira.search_issues(jql_query, startAt=start_idx, maxResults=block_size, expand='changelog')\n",
    "        except JIRAError as e:\n",
    "            if e.status_code == 404:\n",
    "                print(f\"Ignoring not found tickets {block_num}\")\n",
    "                break  # Quit while if face 404 error\n",
    "            else:\n",
    "                raise  # Rerun exception if error was |= from 404 error\n",
    "        else:\n",
    "            if not issues:\n",
    "                break\n",
    "            for issue in issues:\n",
    "                # RegExing main custom fileds\n",
    "                tool_pattern = r\"value='(.*?)'\"\n",
    "                tool_match = re.search(tool_pattern, str(issue.fields.customfield_11897)) #Tool\n",
    "                tool_value = tool_match.group(1) if tool_match else None\n",
    "\n",
    "                area_pattern = r\"value='(.*?)'\"\n",
    "                area_match = re.search(area_pattern, str(issue.fields.customfield_11896)) #Area\n",
    "                area_value = area_match.group(1) if area_match else None\n",
    "\n",
    "                sprint_field = issue.fields.customfield_10007\n",
    "                if isinstance(sprint_field, list):\n",
    "                    sprint_value = ', '.join([str(sprint) for sprint in sprint_field])\n",
    "                else:\n",
    "                    sprint_value = str(sprint_field)\n",
    "\n",
    "                # Converting dates (Created e Updated) in a date filed\n",
    "                created_date = datetime.strptime(issue.fields.created, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                updated_date = datetime.strptime(issue.fields.updated, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                date_diff_days = (updated_date - created_date).days\n",
    "\n",
    "                #custom_create_date = datetime.strptime(issue.fields.customfield_11930, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                #custom_end_date = datetime.strptime(issue.fields.customfield_11931, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "\n",
    "                writer.writerow([\n",
    "                    issue.key,\n",
    "                    tool_value,\n",
    "                    area_value,\n",
    "                    sprint_value,\n",
    "                    issue.fields.summary,\n",
    "                    issue.fields.status.name,\n",
    "                    issue.fields.assignee.displayName if issue.fields.assignee else 'Unassigned',\n",
    "                    issue.fields.reporter.displayName,\n",
    "                    created_date,\n",
    "                    updated_date,\n",
    "                    #issue.fields.customfield_11930, #custom_create_date\n",
    "                    #issue.fields.customfield_11931, #custom_end_date\n",
    "                    date_diff_days,\n",
    "                    issue.fields.priority.name if issue.fields.priority else 'None',\n",
    "                    issue.fields.issuetype.name,\n",
    "                    #issue.fields.labels if issue.fields.labels else '',\n",
    "                    #'\\n'.join([comment.body for comment in issue.fields.comment.comments]) if issue.fields.comment.comments else '',\n",
    "                ])\n",
    "            block_num += 1\n",
    "\n",
    "df = pd.read_csv('./jira_issues.csv')\n",
    "no_of_rows = df['key'].count()\n",
    "print(f\"{no_of_rows} tickets were created and written in jira_issues.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting values\n",
    "\n",
    "Counting how many single values have for the entire csv, for all the column that I want to anonymize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count distinti per ogni colonna:\n",
      "tool_value    10\n",
      "area          15\n",
      "assignee       8\n",
      "reporter      15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "interested_columns = ['tool_value', 'area', 'assignee','reporter',]\n",
    "df = pd.read_csv('./jira_issues.csv',usecols=interested_columns)\n",
    "\n",
    "distinct_counts = df[interested_columns].nunique()\n",
    "\n",
    "# Stampare i risultati\n",
    "print(\"Count distinti per ogni colonna:\")\n",
    "print(distinct_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymizing data\n",
    "\n",
    "### Assignee names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Robert Olsen\n",
      "1          Michele Kent\n",
      "2          Robert Olsen\n",
      "3          Michele Kent\n",
      "4          Robert Olsen\n",
      "             ...       \n",
      "1365     Sandra Charles\n",
      "1366       Michele Kent\n",
      "1367     Sandra Charles\n",
      "1368       Michele Kent\n",
      "1369    Brittney Nelson\n",
      "Name: anonymized_assignee, Length: 1370, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Leggi il file CSV dei problemi Jira\n",
    "#df = pd.read_csv('./jira_issues.csv')\n",
    "\n",
    "# Inizializza il generatore di nomi casuali\n",
    "faker_assignee = Faker()\n",
    "\n",
    "# Dizionario per memorizzare la corrispondenza tra nomi originali e anonimizzati\n",
    "name_dictionary = {}\n",
    "\n",
    "# Funzione per anonimizzare un nome\n",
    "def anonymize_name(name):\n",
    "    if name not in name_dictionary:\n",
    "        # Genera un nuovo nome anonimo se non è già stato anonimizzato\n",
    "        anonymized_name = faker.name()\n",
    "        name_dictionary[name] = anonymized_name\n",
    "    return name_dictionary[name]\n",
    "\n",
    "# Applicare la funzione di anonimizzazione alla colonna 'assignee'\n",
    "df['anonymized_assignee'] = df['assignee'].apply(anonymize_name)\n",
    "\n",
    "print(df['anonymized_assignee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Tool C\n",
      "1       Tool A\n",
      "2       Tool E\n",
      "3       Tool C\n",
      "4       Tool C\n",
      "         ...  \n",
      "1365    Tool E\n",
      "1366    Tool A\n",
      "1367    Tool A\n",
      "1368    Tool E\n",
      "1369    Tool F\n",
      "Name: anonymized_tool, Length: 1370, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Esempio di lista di nomi da anonimizzare per i tool\n",
    "anonymize_tool_list = [\n",
    "    \"Tool A\", \n",
    "    \"Tool B\", \n",
    "    \"Tool C\",\n",
    "    \"Tool D\", \n",
    "    \"Tool E\", \n",
    "    \"Tool F\",\n",
    "]\n",
    "\n",
    "# Dizionario per memorizzare le corrispondenze tra nomi originali e anonimizzati per i tool\n",
    "tool_dictionary = {}\n",
    "\n",
    "# Funzione per anonimizzare un tool\n",
    "def anonymize_tool(tool):\n",
    "    if tool not in tool_dictionary:\n",
    "        # Seleziona un nome anonimizzato dalla lista in modo casuale\n",
    "        anonymized_tool = random.choice(anonymize_tool_list)\n",
    "        tool_dictionary[tool] = anonymized_tool\n",
    "    return tool_dictionary[tool]\n",
    "\n",
    "# Applicare la funzione di anonimizzazione ai tool\n",
    "df['anonymized_tool'] = df['tool_value'].apply(anonymize_tool)\n",
    "\n",
    "# Visualizza il DataFrame con le colonne 'assignee_anonymized' e 'anonymized_tool'\n",
    "print(df['anonymized_tool'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
